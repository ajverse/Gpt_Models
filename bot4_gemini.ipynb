{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3480e852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.169.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Downloading google_auth-2.40.1-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: protobuf in c:\\programdata\\anaconda3\\lib\\site-packages (from google-generativeai) (4.25.3)\n",
      "Requirement already satisfied: pydantic in c:\\programdata\\anaconda3\\lib\\site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from google-generativeai) (4.11.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.1-py2.py3-none-any.whl (216 kB)\n",
      "Downloading google_api_python_client-2.169.0-py3-none-any.whl (13.3 MB)\n",
      "   ---------------------------------------- 0.0/13.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.6/13.3 MB 9.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.9/13.3 MB 7.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.9/13.3 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.5/13.3 MB 6.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.8/13.3 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.4/13.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.4/13.3 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.7/13.3 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.3/13.3 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.1/13.3 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.3/13.3 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.0/4.3 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.4/4.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.7/4.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 6.0 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Installing collected packages: uritemplate, rsa, protobuf, httplib2, grpcio, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.24.2 google-api-python-client-2.169.0 google-auth-2.40.1 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.71.0 grpcio-status-1.71.0 httplib2-0.22.0 proto-plus-1.26.1 protobuf-5.29.4 rsa-4.9.1 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\worka\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25584e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Chatbot is ready! Type 'quit' to exit.\n",
      "Gemini: Okay, let's break down Gen AI – Generative AI. It's a really hot and rapidly evolving field, so here's a comprehensive explanation:\n",
      "\n",
      "**1. What is Generative AI?**\n",
      "\n",
      "At its core, Generative AI refers to a type of artificial intelligence that can *create* new content – text, images, audio, video, code, and more. Unlike traditional AI that primarily analyzes or classifies data, Generative AI *generates* something original.\n",
      "\n",
      "**2. How Does it Work?**\n",
      "\n",
      "* **Machine Learning (ML):** Generative AI relies heavily on machine learning, specifically deep learning.  Neural networks are trained on massive datasets.\n",
      "* **Large Language Models (LLMs):** Many Gen AI systems are built on \"Large Language Models\" (LLMs). These are massive neural networks trained on *huge* amounts of text data – think books, articles, websites, code, etc.  Examples include:\n",
      "    * **GPT-3, GPT-4 (OpenAI):**  Known for their ability to generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.\n",
      "    * **LaMDA (Google):** Focused on conversational AI.\n",
      "    * **Bard (Google):**  Similar to ChatGPT, designed for conversational interactions.\n",
      "* **Generative Process:** The model learns the patterns and relationships within the training data.  Then, when you give it a prompt (a starting point), it uses this learned knowledge to *predict* the next most likely sequence of data – essentially, it \"generates\" something new.\n",
      "\n",
      "**3. Types of Generative AI**\n",
      "\n",
      "* **Text Generation:**  Creating articles, poems, scripts, emails, summaries, chatbots, etc.\n",
      "* **Image Generation:** Producing realistic or artistic images from text descriptions (e.g., DALL-E 2, Midjourney, Stable Diffusion).\n",
      "* **Audio Generation:** Composing music, generating speech, creating sound effects.\n",
      "* **Video Generation:** Creating short video clips from text prompts or existing images. (Still early stage, but rapidly developing)\n",
      "* **Code Generation:**  Writing code in various programming languages based on descriptions. (GitHub Copilot is a prominent example)\n",
      "* **3D Model Generation:** Creating 3D models from text or images.\n",
      "\n",
      "\n",
      "**4. Key Examples of Gen AI Tools & Platforms**\n",
      "\n",
      "* **ChatGPT (OpenAI):** A popular chatbot for conversational AI.\n",
      "* **Google Bard:** Google's conversational AI service.\n",
      "* **DALL-E 2 & Midjourney:** Image generation tools.\n",
      "* **Stable Diffusion:** Open-source image generation model.\n",
      "* **GitHub Copilot:** AI pair programmer for code.\n",
      "* **Jasper.ai:**  AI writing assistant.\n",
      "\n",
      "**5.  Important Considerations & Limitations**\n",
      "\n",
      "* **Bias:** Generative AI models can inherit biases present in their training data, leading to potentially unfair or discriminatory outputs.\n",
      "* **Hallucinations:** LLMs can sometimes \"hallucinate\" – confidently generating incorrect or nonsensical information.\n",
      "* **Copyright & Ownership:** The legal implications of AI-generated content are still being debated.\n",
      "* **Ethical Concerns:**  Misinformation, deepfakes, and other potential misuse are significant concerns.\n",
      "\n",
      "\n",
      "**6.  The Future of Gen AI**\n",
      "\n",
      "Gen AI is still a rapidly evolving field.  We can expect to see:\n",
      "\n",
      "* **Increased sophistication:** Models will become even better at understanding and generating complex content.\n",
      "* **More personalized experiences:** AI will be able to tailor content to individual users' preferences.\n",
      "* **Wider adoption:**  Generative AI will become integrated into more and more applications across various industries.\n",
      "\n",
      "---\n",
      "\n",
      "**Resources for Further Learning:**\n",
      "\n",
      "* **OpenAI:** [https://openai.com/](https://openai.com/)\n",
      "* **Google AI:** [https://ai.google/](https://ai.google/)\n",
      "* **DeepMind:** [https://www.deepmind.com/](https://www.deepmind.com/)\n",
      "* **Towards Data Science (Medium):** [https://towardsdatascience.com/](https://towardsdatascience.com/) (Lots of articles on AI and Gen AI)\n",
      "\n",
      "To help me tailor my explanation further, could you tell me:\n",
      "\n",
      "*   **What specifically are you interested in learning about Gen AI?** (e.g., its applications, how it works, ethical concerns, etc.)\n",
      "Gemini: The color of the sky is a fascinating and constantly changing phenomenon! Here's a breakdown of what it is:\n",
      "\n",
      "*   **Blue:** This is the most common color we perceive. It’s caused by a phenomenon called Rayleigh scattering. Sunlight is made up of all the colors of the rainbow. When sunlight enters the Earth’s atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen). Blue and violet light are scattered more strongly than other colors because they have shorter wavelengths. This scattered blue light is what we see when we look up at the sky.\n",
      "\n",
      "*   **Other Colors:**\n",
      "    *   **Red and Orange:** During sunrise and sunset, the sunlight has to travel through much more of the atmosphere. This longer path scatters away most of the blue light, leaving the longer wavelengths – red and orange – to dominate.\n",
      "    *   **Gray/White:** On cloudy days, the clouds block the sunlight, and the sky appears gray or white.\n",
      "\n",
      "*   **Twilight:** As the sun sets or rises, the light is diffused, and the colors become more muted. You might see a pinkish or purple hue.\n",
      "\n",
      "**In short, the sky is a dynamic mix of colors depending on the time of day, weather conditions, and the amount of sunlight reaching our eyes.**\n",
      "\n",
      "Would you like me to delve deeper into any of these aspects – for example, the science behind Rayleigh scattering, or how it changes with different weather conditions?\n",
      "Gemini: Okay, let’s dive deeper! Here’s a breakdown of the color of the sky, expanding on the key points:\n",
      "\n",
      "**1. Rayleigh Scattering - The Science Behind the Blue:**\n",
      "\n",
      "*   **Short Wavelengths:** As I mentioned, sunlight is composed of all colors.  Blue and violet light have shorter wavelengths than other colors like red and orange.\n",
      "*   **Atmospheric Particles:** The Earth’s atmosphere is filled with tiny air molecules (mostly nitrogen and oxygen).\n",
      "*   **Scattering:** When sunlight hits these particles, it’s scattered in all directions. This is Rayleigh scattering.\n",
      "*   **Why Blue Dominates:**  Blue light is scattered much more effectively than other colors.  It’s like throwing a small ball (blue light) at a bumpy surface – it bounces around everywhere.\n",
      "\n",
      "**2. Sunrise and Sunset - The Red/Orange Shift:**\n",
      "\n",
      "*   **Longer Path:**  During sunrise and sunset, the sun is lower on the horizon.  The sunlight has to travel through a *much* greater distance of the atmosphere to reach our eyes.\n",
      "*   **Blue Light Scattered Away:**  As the sunlight travels this longer path, almost all of the blue light is scattered away before it reaches us.\n",
      "*   **Red and Orange Remain:**  The longer wavelengths – red and orange – are less affected by scattering and can travel through the atmosphere more directly, giving us those beautiful sunset colors.\n",
      "\n",
      "**3. Cloud Cover - Gray and White Skies:**\n",
      "\n",
      "*   **Clouds Block Light:** Clouds are made of water droplets or ice crystals. These particles also scatter light, but they scatter *all* colors more equally.\n",
      "*   **Gray/White Appearance:**  When clouds are present, they block the direct sunlight, resulting in a gray or white sky.\n",
      "\n",
      "**4.  Other Factors:**\n",
      "\n",
      "*   **Humidity:**  High humidity can slightly affect scattering, making the sky appear a bit more gray.\n",
      "*   **Pollution:**  Pollution can also scatter light, leading to hazy or whitish skies.\n",
      "\n",
      "**In essence, the color of the sky is a beautiful example of how light interacts with the atmosphere!**\n",
      "\n",
      "Would you like me to:\n",
      "\n",
      "*   Explain the physics of Rayleigh scattering in more detail?\n",
      "*   Compare and contrast Rayleigh scattering with Mie scattering (which is more important for things like the appearance of halos around the sun)?\n",
      "Gemini: Okay, let’s delve into the physics of Rayleigh scattering – it’s a really important concept!\n",
      "\n",
      "**Rayleigh Scattering Explained:**\n",
      "\n",
      "Rayleigh scattering is the scattering of electromagnetic radiation (like sunlight) by particles of a much smaller wavelength. In our case, it’s the scattering of sunlight by air molecules (nitrogen and oxygen) in the Earth’s atmosphere.\n",
      "\n",
      "Here’s the key:\n",
      "\n",
      "*   **Wavelength Dependence:** Rayleigh scattering is *strongly* dependent on the wavelength of the light. Shorter wavelengths (blue and violet) are scattered much more effectively than longer wavelengths (red and orange). This is why the sky appears blue – blue light is scattered all over the place!\n",
      "\n",
      "*   **How it Works:**  When sunlight enters the atmosphere, it interacts with the air molecules. The light is absorbed and then re-emitted in different directions.  This causes the light to spread out, creating a diffuse glow.\n",
      "\n",
      "**Key Factors & Their Impact:**\n",
      "\n",
      "*   **Wavelength:** As mentioned, shorter wavelengths (blue and violet) are scattered much more.\n",
      "*   **Atmospheric Particles:** The amount and size of the particles in the air (like air molecules) influence how much scattering occurs.  Larger particles scatter more light.\n",
      "*   **Atmospheric Conditions:**  Temperature and humidity can also affect the scattering process.\n",
      "\n",
      "**Why We See Blue, Not Violet?**\n",
      "\n",
      "Violet light is scattered even *more* than blue light. However, our eyes are less sensitive to violet.  Also, the sun emits slightly less violet light than blue light, and some of the violet light is absorbed by the upper atmosphere.  This is why we perceive the sky as blue.\n",
      "\n",
      "**Visualizing it:**\n",
      "\n",
      "Imagine throwing a small ball (blue light) and a large ball (red light) at a bumpy surface. The small ball will bounce around a lot, while the large ball will mostly just roll straight through.\n",
      "\n",
      "---\n",
      "\n",
      "Do you want me to:\n",
      "\n",
      "*   Explain the relationship between wavelength and scattering intensity?\n",
      "*   Discuss how this affects the color of sunsets and sunrises?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m history\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m: [user_input]})\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Compose the conversation for Gemini\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(history)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Get Gemini's reply\u001b[39;00m\n\u001b[0;32m     23\u001b[0m reply \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m    332\u001b[0m             request,\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[0;32m    836\u001b[0m     request,\n\u001b[0;32m    837\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m    838\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    839\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    840\u001b[0m )\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    294\u001b[0m     target,\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    296\u001b[0m     sleep_generator,\n\u001b[0;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\grpc\\_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    270\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_with_call(\n\u001b[0;32m    278\u001b[0m         request,\n\u001b[0;32m    279\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    280\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    281\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[0;32m    282\u001b[0m         wait_for_ready\u001b[38;5;241m=\u001b[39mwait_for_ready,\n\u001b[0;32m    283\u001b[0m         compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    284\u001b[0m     )\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\grpc\\_interceptor.py:329\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m--> 329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[0;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[0;32m    331\u001b[0m )\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mresult(), call\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\grpc.py:79\u001b[0m, in \u001b[0;36m_LoggingClientInterceptor.intercept_unary_unary\u001b[1;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[0;32m     64\u001b[0m     grpc_request \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m: request_payload,\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequestMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrpc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[0;32m     68\u001b[0m     }\n\u001b[0;32m     69\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     71\u001b[0m         extra\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m         },\n\u001b[0;32m     77\u001b[0m     )\n\u001b[1;32m---> 79\u001b[0m response \u001b[38;5;241m=\u001b[39m continuation(client_call_details, request)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     response_metadata \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtrailing_metadata()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\grpc\\_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[1;34m(new_details, request)\u001b[0m\n\u001b[0;32m    306\u001b[0m (\n\u001b[0;32m    307\u001b[0m     new_method,\n\u001b[0;32m    308\u001b[0m     new_timeout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m     new_compression,\n\u001b[0;32m    313\u001b[0m ) \u001b[38;5;241m=\u001b[39m _unwrap_client_call_details(new_details, client_call_details)\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thunk(new_method)\u001b[38;5;241m.\u001b[39mwith_call(\n\u001b[0;32m    316\u001b[0m         request,\n\u001b[0;32m    317\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mnew_timeout,\n\u001b[0;32m    318\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mnew_metadata,\n\u001b[0;32m    319\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mnew_credentials,\n\u001b[0;32m    320\u001b[0m         wait_for_ready\u001b[38;5;241m=\u001b[39mnew_wait_for_ready,\n\u001b[0;32m    321\u001b[0m         compression\u001b[38;5;241m=\u001b[39mnew_compression,\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\grpc\\_channel.py:1195\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_call\u001b[39m(\n\u001b[0;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1185\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, grpc\u001b[38;5;241m.\u001b[39mCall]:\n\u001b[0;32m   1192\u001b[0m     (\n\u001b[0;32m   1193\u001b[0m         state,\n\u001b[0;32m   1194\u001b[0m         call,\n\u001b[1;32m-> 1195\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[0;32m   1196\u001b[0m         request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1197\u001b[0m     )\n\u001b[0;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\grpc\\_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[0;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[0;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[1;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m call\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAa9ZO8evpCKFgjg0UfwHbhjFNj5S7_2ss\")\n",
    "\n",
    "model = genai.GenerativeModel(\"models/gemma-3-1b-it\")\n",
    "\n",
    "print(\"Gemini Chatbot is ready! Type 'quit' to exit.\")\n",
    "\n",
    "history = []\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    # Add user message to history\n",
    "    history.append({\"role\": \"user\", \"parts\": [user_input]})\n",
    "\n",
    "    # Compose the conversation for Gemini\n",
    "    response = model.generate_content(history)\n",
    "\n",
    "    # Get Gemini's reply\n",
    "    reply = response.text\n",
    "    print(\"Gemini:\", reply)\n",
    "\n",
    "    # Add Gemini's reply to history\n",
    "    history.append({\"role\": \"model\", \"parts\": [reply]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35c592e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001 - A legacy text-only model optimized for chat conversations\n",
      "models/text-bison-001 - A legacy model that understands text and generates text as an output\n",
      "models/embedding-gecko-001 - Obtain a distributed representation of a text.\n",
      "models/gemini-1.0-pro-vision-latest - The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
      "models/gemini-pro-vision - The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
      "models/gemini-1.5-pro-latest - Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.\n",
      "models/gemini-1.5-pro-001 - Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
      "models/gemini-1.5-pro-002 - Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.\n",
      "models/gemini-1.5-pro - Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
      "models/gemini-1.5-flash-latest - Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "models/gemini-1.5-flash-001 - Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
      "models/gemini-1.5-flash-001-tuning - Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
      "models/gemini-1.5-flash - Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "models/gemini-1.5-flash-002 - Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.\n",
      "models/gemini-1.5-flash-8b - Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "models/gemini-1.5-flash-8b-001 - Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "models/gemini-1.5-flash-8b-latest - Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "models/gemini-1.5-flash-8b-exp-0827 - Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
      "models/gemini-1.5-flash-8b-exp-0924 - Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
      "models/gemini-2.5-pro-exp-03-25 - Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "models/gemini-2.5-pro-preview-03-25 - Gemini 2.5 Pro Preview 03-25\n",
      "models/gemini-2.5-flash-preview-04-17 - Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "models/gemini-2.5-flash-preview-04-17-thinking - Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "models/gemini-2.5-pro-preview-05-06 - Preview release (May 6th, 2025) of Gemini 2.5 Pro\n",
      "models/gemini-2.0-flash-exp - Gemini 2.0 Flash Experimental\n",
      "models/gemini-2.0-flash - Gemini 2.0 Flash\n",
      "models/gemini-2.0-flash-001 - Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\n",
      "models/gemini-2.0-flash-exp-image-generation - Gemini 2.0 Flash (Image Generation) Experimental\n",
      "models/gemini-2.0-flash-lite-001 - Stable version of Gemini 2.0 Flash Lite\n",
      "models/gemini-2.0-flash-lite - Gemini 2.0 Flash-Lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05 - Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
      "models/gemini-2.0-flash-lite-preview - Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
      "models/gemini-2.0-pro-exp - Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "models/gemini-2.0-pro-exp-02-05 - Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "models/gemini-exp-1206 - Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 - Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "models/gemini-2.0-flash-thinking-exp - Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "models/gemini-2.0-flash-thinking-exp-1219 - Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "models/learnlm-1.5-pro-experimental - Alias that points to the most recent stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.\n",
      "models/learnlm-2.0-flash-experimental - LearnLM 2.0 Flash Experimental\n",
      "models/gemma-3-1b-it - \n",
      "models/gemma-3-4b-it - \n",
      "models/gemma-3-12b-it - \n",
      "models/gemma-3-27b-it - \n",
      "models/embedding-001 - Obtain a distributed representation of a text.\n",
      "models/text-embedding-004 - Obtain a distributed representation of a text.\n",
      "models/gemini-embedding-exp-03-07 - Obtain a distributed representation of a text.\n",
      "models/gemini-embedding-exp - Obtain a distributed representation of a text.\n",
      "models/aqa - Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.\n",
      "models/imagen-3.0-generate-002 - Vertex served Imagen 3.0 002 model\n",
      "models/gemini-2.0-flash-live-001 - Gemini 2.0 Flash 001\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAa9ZO8evpCKFgjg0UfwHbhjFNj5S7_2ss\")\n",
    "\n",
    "for model in genai.list_models():\n",
    "    print(model.name, \"-\", model.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea98b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable the model from the Google Cloud API library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ccc30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
